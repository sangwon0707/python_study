# 손글씨 숫자 인식 모델: 코드 심층 분석

이 문서는 `test06_convolution_image.ipynb`의 코드를 한 단계씩 따라가며, 각 코드 라인이 어떤 역할을 하고 데이터(변수)가 어떻게 변환되고 전달되는지 설명합니다.

## 1단계: 데이터 준비

모델을 학습시키기 전, 컴퓨터가 이해할 수 있는 형태로 데이터를 가공해야 합니다.

### 1. 데이터 불러오기
- **코드**: `(X_train, Y_class_train), (X_test, Y_class_test) = mnist.load_data()`
- **설명**:
    - `mnist.load_data()` 함수는 손글씨 숫자 이미지와 정답이 들어있는 `MNIST` 데이터셋을 불러옵니다.
    - 데이터는 '학습용'과 '시험용' 두 세트로 나뉩니다.
- **생성된 변수**:
    - `X_train`: 학습에 사용할 이미지 데이터 60,000개. 각 이미지는 28x28 크기의 숫자 격자판입니다.
    - `Y_class_train`: `X_train`에 있는 각 이미지의 실제 정답 숫자 (예: 5, 0, 4, ...).
    - `X_test`: 모델의 성능을 시험하기 위한 이미지 데이터 10,000개.
    - `Y_class_test`: `X_test`에 있는 각 이미지의 실제 정답 숫자.

### 2. 데이터 형태 변환 (Reshape)
- **코드**: `X_train = X_train.reshape(X_train.shape[0], 784)`
- **설명**:
    - 인공지능 모델의 입력층은 1차원 배열 형태를 기대하므로, 2차원(28x28)인 이미지 데이터를 1차원(784)으로 쭉 펴주는 작업입니다.
- **변수 변화**:
    - `X_train`의 구조가 (60000, 28, 28)에서 (60000, 784)로 변경됩니다.
    - **다음 단계**: 이 1차원 데이터는 이제 모델이 직접 입력받을 수 있는 형태가 되었습니다.

### 3. 데이터 정규화 (Normalization)
- **코드**: `X_train = X_train / 255`
- **설명**:
    - 이미지의 각 픽셀이 갖는 밝기 값(0~255)을 255로 나누어 0~1 사이의 소수 값으로 변환합니다.
    - 데이터의 범위를 줄여주면 모델이 더 안정적이고 빠르게 학습할 수 있습니다.
- **변수 변화**:
    - `X_train` 내부의 모든 값이 0~255의 정수에서 0~1 사이의 실수로 변경됩니다.
    - **다음 단계**: `X_train`은 이제 모델 학습에 사용될 최종 준비를 마쳤습니다. `X_test`도 동일한 과정을 거쳐 시험에 사용될 준비를 합니다.

### 4. 정답 데이터 형식 변환 (One-Hot Encoding)
- **코드**: `Y_train = to_categorical(Y_class_train, 10)`
- **설명**:
    - 모델의 출력은 10개의 뉴런(0~9)에서 각각의 확률을 계산하는 방식입니다. 따라서 실제 정답의 형식도 이에 맞춰줘야 합니다.
    - 이 코드는 정답 `5`를 `[0,0,0,0,0,1,0,0,0,0]` 와 같이 5번째 위치만 1로 표시되는 배열로 변환합니다.
- **생성된 변수**:
    - `Y_class_train` (예: `[5, 0, 4, ...]`)을 사용하여 `Y_train`이라는 새로운 변수가 생성됩니다.
    - `Y_train`은 원-핫 인코딩된 정답 배열을 담고 있습니다.
    - **다음 단계**: `Y_train`은 학습 시 모델의 예측값과 비교하여 '오차'를 계산하는 데 사용됩니다. `Y_test`도 동일한 과정을 거칩니다.

## 2단계: 인공지능 모델 설계 및 설정

데이터 준비가 끝났으니, 이제 학습을 수행할 인공지능 '뇌'(모델)를 만듭니다.

### 1. 모델 뼈대 생성
- **코드**: `model = Sequential()`
- **설명**:
    - `Sequential`은 신경망의 각 층(Layer)을 차곡차곡 순서대로 쌓을 수 있게 해주는 모델의 뼈대입니다.
- **생성된 변수**:
    - `model`: 비어있는 신경망 모델 객체.
    - **다음 단계**: 이 `model` 변수에 필요한 층들을 추가하게 됩니다.

### 2. 모델 층(Layer) 추가
- **코드**:
    - `model.add(Input(shape=(784,)))`
    - `model.add(Dense(512, activation='relu'))`
    - `model.add(Dense(10, activation='softmax'))`
- **설명**:
    - **Input**: 784개의 숫자로 이루어진 데이터가 들어올 입력층을 정의합니다.
    - **Dense(512)**: 512개의 신경세포(뉴런)를 가진 은닉층입니다. 입력 데이터의 특징을 추출하고 학습하는 핵심적인 '뇌' 부분입니다.
    - **Dense(10)**: 10개의 뉴런을 가진 출력층입니다. 0~9 각 숫자에 대한 최종 예측 확률을 출력합니다. `softmax` 활성화 함수는 10개 뉴런의 출력 총합이 1이 되도록 만들어, 확률적인 해석을 가능하게 합니다.
- **변수 변화**:
    - `model` 변수에 3개의 층이 순서대로 쌓여 신경망의 구조가 완성됩니다.

### 3. 모델 학습 환경 설정 (Compile)
- **코드**: `model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])`
- **설명**:
    - 모델을 훈련하기 전, 학습 방식을 설정합니다.
    - `loss`: 모델의 예측이 얼마나 틀렸는지를 측정하는 '오차 함수'를 지정합니다.
    - `optimizer`: 계산된 오차를 바탕으로 모델의 가중치를 어떻게 업데이트할지 결정하는 '최적화 알고리즘'을 지정합니다.
    - `metrics`: 훈련 과정을 모니터링할 지표로 '정확도'를 사용하겠다고 설정합니다.
- **변수 변화**:
    - `model` 변수에 학습에 필요한 설정들이 추가되어 훈련을 시작할 수 있는 상태가 됩니다.

## 3단계: 모델 학습 및 평가

이제 준비된 데이터와 설계된 모델을 가지고 본격적인 학습을 시작합니다.

### 1. 모델 학습 실행 (Fit)
- **코드**: `history = model.fit(X_train, Y_train, ...)`
- **설명**:
    - `fit` 함수는 준비된 학습 데이터(`X_train`, `Y_train`)를 모델에 주입하여 학습을 시작하라는 명령입니다.
    - 모델은 이미지를 보고 예측하고, 정답과 비교하여 오차를 줄이는 과정을 지정된 횟수(epoch)만큼 반복합니다.
- **변수 변화**:
    - `model`의 내부 가중치(파라미터)들이 학습을 통해 계속 업데이트됩니다. 즉, 모델이 점점 똑똑해집니다.
- **생성된 변수**:
    - `history`: 매 학습 사이클마다의 오차(loss)와 정확도(accuracy) 같은 훈련 과정의 기록이 저장되는 변수입니다.
    - **다음 단계**: `history` 변수는 학습이 잘 되었는지 그래프로 확인하는 데 사용됩니다.

### 2. 모델 최종 평가 (Evaluate)
- **코드**: `model.evaluate(X_test, Y_test)`
- **설명**:
    - 학습이 완료된 `model`에게 한 번도 본 적 없는 시험용 데이터(`X_test`, `Y_test`)를 주고 최종 성능(정확도)을 평가합니다.
- **결과**: 이 모델은 약 98.21%의 정확도를 달성했습니다.

### 3. 특정 이미지로 예측하기
- **코드**:
    - `image = X_test[2025]`
    - `prediction = model.predict(image.reshape(1, 784))`
    - `predicted_label = prediction.argmax()`
- **설명**:
    - 시험용 데이터에서 2025번째 이미지를 `image` 변수에 저장합니다.
    - 학습된 `model`을 사용하여 이 `image`가 어떤 숫자인지 예측하고, 그 결과를 `prediction` 변수에 저장합니다. `prediction`은 10개의 숫자에 대한 확률 배열입니다.
    - `argmax()` 함수는 `prediction` 배열에서 가장 높은 확률 값을 가진 위치(인덱스)를 찾아 `predicted_label` 변수에 저장합니다. 이 값이 바로 모델의 최종 예측 숫자입니다.
